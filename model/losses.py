import torch
import torch.nn.functional as F


def cosine_similarity_loss(output_de_st_list):
    loss = 0
    for instance in output_de_st_list:
        _, _, h, w = instance.shape
        loss += torch.sum(instance) / (h * w)
    return loss

def smoothL1_loss(output_de_st_list,mask):
    loss = 0
    for instance in output_de_st_list:
        _, _, h, w = instance.shape
        mask_t = F.interpolate(
                mask,
                size=[h,w],
                mode="bilinear",
                align_corners=False,
            )
        loss += F.smooth_l1_loss(instance,mask_t)
    return loss

def focal_loss(inputs, targets, alpha=-1, gamma=4, reduction="mean"):
    inputs = inputs.float()
    targets = targets.float()
    ce_loss = F.binary_cross_entropy(inputs, targets, reduction="none")
    p_t = inputs * targets + (1 - inputs) * (1 - targets)
    loss = ce_loss * ((1 - p_t) ** gamma)

    if alpha >= 0:
        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)
        loss = alpha_t * loss

    if reduction == "mean":
        loss = loss.mean()
    elif reduction == "sum":
        loss = loss.sum()

    return loss


def l1_loss(inputs, targets, reduction="mean"):
    return F.l1_loss(inputs, targets, reduction=reduction)
